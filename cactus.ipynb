{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN1OgPG+DptKOB54i7BdLLr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ADAMFUTUR/ADAMFUTUR/blob/main/cactus.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ipUXSeE98KUU",
        "outputId": "1942bd8d-9a1b-4760-ba70-d2069ab88938"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CactiViT-materials'...\n",
            "remote: Enumerating objects: 5932, done.\u001b[K\n",
            "remote: Counting objects: 100% (45/45), done.\u001b[K\n",
            "remote: Compressing objects: 100% (40/40), done.\u001b[K\n",
            "remote: Total 5932 (delta 14), reused 14 (delta 5), pack-reused 5887 (from 1)\u001b[K\n",
            "Receiving objects: 100% (5932/5932), 735.39 MiB | 24.24 MiB/s, done.\n",
            "Resolving deltas: 100% (48/48), done.\n",
            "Updating files: 100% (6037/6037), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/AnasBerka/CactiViT-materials.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms, models\n",
        "from transformers import ViTForImageClassification, ViTFeatureExtractor\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n"
      ],
      "metadata": {
        "id": "c8tvC1Z98vg1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "metadata": {
        "id": "E7kbBtL89qX8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Data preprocessing for ViT\n",
        "vit_transform = ViTFeatureExtractor.from_pretrained(\"google/vit-base-patch16-224\")\n",
        "cnn_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "# Load CIFAR-10 dataset (replace with your dataset, e.g., cactus images)\n",
        "train_dataset_vit = datasets.CIFAR10(root=\"./data\", train=True, download=True,\n",
        "                                     transform=lambda x: vit_transform(Image.fromarray(np.array(x)))[\"pixel_values\"][0])\n",
        "test_dataset_vit = datasets.CIFAR10(root=\"./data\", train=False, download=True,\n",
        "                                    transform=lambda x: vit_transform(Image.fromarray(np.array(x)))[\"pixel_values\"][0])\n",
        "train_dataset_cnn = datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=cnn_transform)\n",
        "test_dataset_cnn = datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=cnn_transform)\n",
        "\n",
        "train_loader_vit = DataLoader(train_dataset_vit, batch_size=32, shuffle=True)\n",
        "test_loader_vit = DataLoader(test_dataset_vit, batch_size=32, shuffle=False)\n",
        "train_loader_cnn = DataLoader(train_dataset_cnn, batch_size=32, shuffle=True)\n",
        "test_loader_cnn = DataLoader(test_dataset_cnn, batch_size=32, shuffle=False)\n",
        "\n",
        "# Vision Transformer (ViT)\n",
        "vit_model = ViTForImageClassification.from_pretrained(\"google/vit-base-patch16-224\", num_labels=10, ignore_mismatched_sizes=True)\n",
        "vit_model = vit_model.to(device)\n",
        "vit_optimizer = optim.Adam(vit_model.parameters(), lr=1e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# ResNet (Deep Learning Model)\n",
        "resnet_model = models.resnet18(pretrained=True)\n",
        "resnet_model.fc = nn.Linear(resnet_model.fc.in_features, 10)\n",
        "resnet_model = resnet_model.to(device)\n",
        "resnet_optimizer = optim.Adam(resnet_model.parameters(), lr=1e-3)\n",
        "\n",
        "# EfficientNet (Deep Learning Model)\n",
        "efficientnet_model = models.efficientnet_b0(pretrained=True)\n",
        "efficientnet_model.classifier[1] = nn.Linear(efficientnet_model.classifier[1].in_features, 10)\n",
        "efficientnet_model = efficientnet_model.to(device)\n",
        "efficientnet_optimizer = optim.Adam(efficientnet_model.parameters(), lr=1e-3)\n",
        "\n",
        "# Training function for deep learning models\n",
        "def train_model(model, train_loader, optimizer, criterion, epochs=3):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs) if isinstance(model, models.ResNet) or isinstance(model, models.EfficientNet) else model(inputs).logits\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "        print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}\")\n",
        "\n",
        "# Evaluation function for deep learning models\n",
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs) if isinstance(model, models.ResNet) or isinstance(model, models.EfficientNet) else model(inputs).logits\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return correct / total\n",
        "\n",
        "# Train and evaluate ViT\n",
        "print(\"Training ViT...\")\n",
        "train_model(vit_model, train_loader_vit, vit_optimizer, criterion)\n",
        "vit_accuracy = evaluate_model(vit_model, test_loader_vit)\n",
        "print(f\"ViT Accuracy: {vit_accuracy:.4f}\")\n",
        "\n",
        "# Train and evaluate ResNet\n",
        "print(\"Training ResNet...\")\n",
        "train_model(resnet_model, train_loader_cnn, resnet_optimizer, criterion)\n",
        "resnet_accuracy = evaluate_model(resnet_model, test_loader_cnn)\n",
        "print(f\"ResNet Accuracy: {resnet_accuracy:.4f}\")\n",
        "\n",
        "# Train and evaluate EfficientNet\n",
        "print(\"Training EfficientNet...\")\n",
        "train_model(efficientnet_model, train_loader_cnn, efficientnet_optimizer, criterion)\n",
        "efficientnet_accuracy = evaluate_model(efficientnet_model, test_loader_cnn)\n",
        "print(f\"EfficientNet Accuracy: {efficientnet_accuracy:.4f}\")\n",
        "\n",
        "# Prepare data for traditional ML models (flatten images)\n",
        "def prepare_ml_data(dataset):\n",
        "    X, y = [], []\n",
        "    for img, label in dataset:\n",
        "        X.append(np.array(img).flatten())\n",
        "        y.append(label)\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "X_train_ml, y_train_ml = prepare_ml_data(train_dataset_cnn)\n",
        "X_test_ml, y_test_ml = prepare_ml_data(test_dataset_cnn)\n",
        "\n",
        "# Random Forest\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train_ml, y_train_ml)\n",
        "rf_accuracy = accuracy_score(y_test_ml, rf_model.predict(X_test_ml))\n",
        "print(f\"Random Forest Accuracy: {rf_accuracy:.4f}\")\n",
        "\n",
        "# SVM\n",
        "svm_model = SVC(kernel=\"rbf\", random_state=42)\n",
        "svm_model.fit(X_train_ml[:5000], y_train_ml[:5000])  # Subset for speed\n",
        "svm_accuracy = accuracy_score(y_test_ml, svm_model.predict(X_test_ml))\n",
        "print(f\"SVM Accuracy: {svm_accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "7S7joDYS90JI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "cIjb_EqL8PXo"
      }
    }
  ]
}